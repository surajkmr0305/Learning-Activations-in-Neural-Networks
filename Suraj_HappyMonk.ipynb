{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the Dataset\n",
    "dataset = pd.read_csv ('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape of the Dataset\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column names in the Dataset\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#Columns information\n",
    "dataset.info ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First 5 rows\n",
    "dataset.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVING UNNEEDED FEATURES¶\n",
    "#The columns id and Unnamed: 32 don't play any role in the prediction and hence we can drop them from the dataset.\n",
    "dataset.drop ('id', axis = 1, inplace = True)\n",
    "dataset.drop ('Unnamed: 32', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape of the dataset\n",
    "dataset.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First 5 rows\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0        False        False         False           False      False   \n",
       "1        False        False         False           False      False   \n",
       "2        False        False         False           False      False   \n",
       "3        False        False         False           False      False   \n",
       "4        False        False         False           False      False   \n",
       "..         ...          ...           ...             ...        ...   \n",
       "564      False        False         False           False      False   \n",
       "565      False        False         False           False      False   \n",
       "566      False        False         False           False      False   \n",
       "567      False        False         False           False      False   \n",
       "568      False        False         False           False      False   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0              False             False           False                False   \n",
       "1              False             False           False                False   \n",
       "2              False             False           False                False   \n",
       "3              False             False           False                False   \n",
       "4              False             False           False                False   \n",
       "..               ...               ...             ...                  ...   \n",
       "564            False             False           False                False   \n",
       "565            False             False           False                False   \n",
       "566            False             False           False                False   \n",
       "567            False             False           False                False   \n",
       "568            False             False           False                False   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0            False  ...         False          False            False   \n",
       "1            False  ...         False          False            False   \n",
       "2            False  ...         False          False            False   \n",
       "3            False  ...         False          False            False   \n",
       "4            False  ...         False          False            False   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564          False  ...         False          False            False   \n",
       "565          False  ...         False          False            False   \n",
       "566          False  ...         False          False            False   \n",
       "567          False  ...         False          False            False   \n",
       "568          False  ...         False          False            False   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0         False             False              False            False   \n",
       "1         False             False              False            False   \n",
       "2         False             False              False            False   \n",
       "3         False             False              False            False   \n",
       "4         False             False              False            False   \n",
       "..          ...               ...                ...              ...   \n",
       "564       False             False              False            False   \n",
       "565       False             False              False            False   \n",
       "566       False             False              False            False   \n",
       "567       False             False              False            False   \n",
       "568       False             False              False            False   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                   False           False                    False  \n",
       "1                   False           False                    False  \n",
       "2                   False           False                    False  \n",
       "3                   False           False                    False  \n",
       "4                   False           False                    False  \n",
       "..                    ...             ...                      ...  \n",
       "564                 False           False                    False  \n",
       "565                 False           False                    False  \n",
       "566                 False           False                    False  \n",
       "567                 False           False                    False  \n",
       "568                 False           False                    False  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHECKING FOR MISSING DATA\n",
    "#Next we need to check for any missing data that might be present in the dataset. For this, we will be using the isna () function of the Pandas library\n",
    "dataset.isna ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all the entries of the isna () function are false, we can conclude that there is no missing data in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diagnosis</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_mean</th>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_mean</th>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_mean</th>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_mean</th>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_mean</th>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_mean</th>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_mean</th>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_mean</th>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_se</th>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_se</th>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_se</th>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_se</th>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_se</th>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_se</th>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_se</th>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_se</th>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_se</th>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_worst</th>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_worst</th>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_worst</th>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_worst</th>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_worst</th>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_worst</th>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_worst</th>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_worst</th>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_worst</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         unique count\n",
       "diagnosis                           2\n",
       "radius_mean                       456\n",
       "texture_mean                      479\n",
       "perimeter_mean                    522\n",
       "area_mean                         539\n",
       "smoothness_mean                   474\n",
       "compactness_mean                  537\n",
       "concavity_mean                    537\n",
       "concave points_mean               542\n",
       "symmetry_mean                     432\n",
       "fractal_dimension_mean            499\n",
       "radius_se                         540\n",
       "texture_se                        519\n",
       "perimeter_se                      533\n",
       "area_se                           528\n",
       "smoothness_se                     547\n",
       "compactness_se                    541\n",
       "concavity_se                      533\n",
       "concave points_se                 507\n",
       "symmetry_se                       498\n",
       "fractal_dimension_se              545\n",
       "radius_worst                      457\n",
       "texture_worst                     511\n",
       "perimeter_worst                   514\n",
       "area_worst                        544\n",
       "smoothness_worst                  411\n",
       "compactness_worst                 529\n",
       "concavity_worst                   539\n",
       "concave points_worst              492\n",
       "symmetry_worst                    500\n",
       "fractal_dimension_worst           535"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHECKING THE NUMBER OF UNIQUE VALUES\n",
    "#Next we will be checking how many unique values does each feature have, in order to get a much better understanding of the dataset we are working on.\n",
    "dict = {}\n",
    "for i in list(dataset.columns):\n",
    "    dict[i] = dataset[i].value_counts().shape[0]\n",
    "\n",
    "pd.DataFrame(dict,index=[\"unique count\"]).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result of the above function we can see that we have only 1 categorical data feature and the rest are continuous data features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENCODING THE CATEGORICAL VARIABLE\n",
    "To ensure that the entire dataset is of a continuous numerical form, we will be encoding the categorial variable DIAGNOSIS and converting into a numerical form, preferably into 0s and 1s.\n",
    "\n",
    "For this, we will be making use of the LabelEncoder class from the Preprocessing module of the Sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>...</td>\n",
       "      <td>15.09</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1        17.99         10.38          122.80     1001.0   \n",
       "1          1        20.57         17.77          132.90     1326.0   \n",
       "2          1        19.69         21.25          130.00     1203.0   \n",
       "3          1        11.42         20.38           77.58      386.1   \n",
       "4          1        20.29         14.34          135.10     1297.0   \n",
       "5          1        12.45         15.70           82.57      477.1   \n",
       "6          1        18.25         19.98          119.60     1040.0   \n",
       "7          1        13.71         20.83           90.20      577.9   \n",
       "8          1        13.00         21.82           87.50      519.8   \n",
       "9          1        12.46         24.04           83.97      475.9   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760         0.30010              0.14710   \n",
       "1          0.08474           0.07864         0.08690              0.07017   \n",
       "2          0.10960           0.15990         0.19740              0.12790   \n",
       "3          0.14250           0.28390         0.24140              0.10520   \n",
       "4          0.10030           0.13280         0.19800              0.10430   \n",
       "5          0.12780           0.17000         0.15780              0.08089   \n",
       "6          0.09463           0.10900         0.11270              0.07400   \n",
       "7          0.11890           0.16450         0.09366              0.05985   \n",
       "8          0.12730           0.19320         0.18590              0.09353   \n",
       "9          0.11860           0.23960         0.22730              0.08543   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "5         0.2087  ...         15.47          23.75           103.40   \n",
       "6         0.1794  ...         22.88          27.66           153.20   \n",
       "7         0.2196  ...         17.06          28.14           110.60   \n",
       "8         0.2350  ...         15.49          30.73           106.20   \n",
       "9         0.2030  ...         15.09          40.68            97.65   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "5       741.6            0.1791             0.5249           0.5355   \n",
       "6      1606.0            0.1442             0.2576           0.3784   \n",
       "7       897.0            0.1654             0.3682           0.2678   \n",
       "8       739.3            0.1703             0.5401           0.5390   \n",
       "9       711.4            0.1853             1.0580           1.1050   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "5                0.1741          0.3985                  0.12440  \n",
       "6                0.1932          0.3063                  0.08368  \n",
       "7                0.1556          0.3196                  0.11510  \n",
       "8                0.2060          0.4378                  0.10720  \n",
       "9                0.2210          0.4366                  0.20750  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_Y = LabelEncoder()\n",
    "dataset.diagnosis = labelencoder_Y.fit_transform(dataset.diagnosis)\n",
    "dataset.head (10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table, it is clearly visible that the DIAGNOSIS feature is taking 0s and 1s as values.\n",
    "\n",
    "0 --> Benign\n",
    "\n",
    "1 --> Malignant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPLITTING DATASET INTO DEPENDENT AND INDEPENDENT VARIABLES\n",
    "Now finally we will be splitting the updated dataset we have into two parts. The first is a collection of the independent variables and is called the MATRIX OF FEATURES. The other is a collection of the dependent variables and is known as RESPONSE FEATURE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.iloc [:, 1:].values\n",
    "Y = dataset.iloc [:, 0].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split (X, Y, test_size = 0.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143, 30)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we'll be using one of the most used feature scaling method there is, STANDARD SCALER. This method assumes your data to be normally distributed within each feature and scales them in such a way that the distribution becomes centred around 0 with a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler ()\n",
    "X_train = sc.fit_transform (X_train)\n",
    "X_test = sc.transform (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.30575375  2.59521918  0.46246107  0.16827218  0.60422155  2.04417806\n",
      "   2.09352879  1.16366689  1.18198433  1.28429612 -0.52163603 -0.03835455\n",
      "  -0.25571081 -0.38216301 -0.77588337  1.24952899  1.41506722  0.66874898\n",
      "   0.12308074  0.80508841  0.24441187  2.73052064  0.61360382  0.04361489\n",
      "   0.42657507  3.47782867  4.41644563  1.81549702  2.10164609  3.38609913]\n",
      " [ 0.23351721 -0.05334893  0.20573083  0.08631508 -0.47424506 -0.12457556\n",
      "  -0.36621964 -0.01640861  0.26394984 -0.63317355 -0.42668937 -0.47901876\n",
      "  -0.34672558 -0.33704942 -0.54691279 -0.25816563 -0.55887941  0.005534\n",
      "  -0.66616947 -0.36984213 -0.01035708  0.08241715  0.04661672 -0.13397845\n",
      "  -0.04171878  0.30956727 -0.44003546  0.5143837   0.14721854  0.05182385]\n",
      " [ 0.15572401  0.18345881  0.11343692  0.07856238  0.15993389 -0.63952448\n",
      "  -0.18324755  0.09622333 -0.8163076  -0.52992519  0.21204267  0.02165808\n",
      "   0.14122792  0.08014965 -0.42190198 -0.78467094 -0.4022654  -0.11734193\n",
      "  -0.80990285 -0.62764173  0.55535036  0.83058615  0.46028588  0.42007226\n",
      "   0.63820786 -0.44181701  0.10469918  0.69446859  0.263409   -0.10011179]\n",
      " [-1.05562722 -0.68560261 -1.07268096 -0.91710572 -0.15389409 -1.07260771\n",
      "  -0.98593539 -1.10932235  0.28607116 -0.1184067  -0.69357579 -0.44644047\n",
      "  -0.735087   -0.57887451  0.02114151 -1.02626671 -0.73651087 -0.99874045\n",
      "  -0.61740279 -0.44365051 -1.01338447 -0.62268029 -1.05206542 -0.85127324\n",
      "  -0.1677979  -1.08156335 -1.11020629 -1.36285119 -0.3400877  -0.58500017]\n",
      " [-0.63054296 -0.43040203 -0.66038107 -0.6186268  -0.92360615 -0.94539197\n",
      "  -0.77517168 -0.66634607  0.2492023  -0.83524536 -0.70531465  0.01822879\n",
      "  -0.79322209 -0.560382    0.18598737 -0.59793558 -0.60091434 -0.51306545\n",
      "  -0.31966938 -0.73393993 -0.65028855  0.01222645 -0.66934913 -0.62691815\n",
      "   0.21043944 -0.51507536 -0.6795224  -0.34852305  0.38827039 -0.81765163]]\n"
     ]
    }
   ],
   "source": [
    "print (X_train [:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.58502337e-01 -1.23049032e+00  2.53691428e-01 -7.21453404e-05\n",
      "   4.81009638e-01  1.55141337e+00  7.10234684e-01  3.62700248e-01\n",
      "   1.02713514e+00  1.65894019e+00  4.65809179e-01  4.86327343e-01\n",
      "   9.03655260e-01  1.62451465e-01  9.57103281e-01  1.47051757e+00\n",
      "   7.09626219e-01  6.24639667e-01  7.85280914e-01  5.58589606e-01\n",
      "   3.17700683e-02 -1.16984866e+00  1.91256286e-01 -1.34991341e-01\n",
      "  -4.62216093e-02  7.01791156e-01  2.54378520e-01 -5.73858182e-02\n",
      "  -8.68965562e-02  4.88638842e-01]\n",
      " [-2.63803596e-01 -1.54509521e-01 -2.39617537e-01 -3.36483918e-01\n",
      "   1.40147509e+00  3.63673764e-01  4.28545703e-01  6.28921185e-01\n",
      "   1.18198433e+00  7.31179866e-01 -4.28760938e-01 -5.72124078e-01\n",
      "  -4.77291260e-01 -3.49648715e-01 -1.58278149e-01 -1.36069442e-01\n",
      "  -9.48002516e-02  4.96433119e-02 -3.82552731e-01 -7.74338066e-02\n",
      "  -1.26708259e-01  3.63179927e-01 -1.35629132e-01 -2.19061193e-01\n",
      "   2.08811767e+00  1.04604055e+00  1.13135222e+00  1.41330744e+00\n",
      "   1.77388495e+00  2.02105229e+00]\n",
      " [-3.24926823e-01 -7.61473048e-01 -3.54078114e-01 -3.94352280e-01\n",
      "   2.92567891e-01 -4.93658276e-01 -3.39182524e-01 -3.87326046e-01\n",
      "  -2.85396093e-01  2.78362029e-01 -6.97028395e-01 -7.95199617e-01\n",
      "  -7.94651641e-01 -4.83363762e-01  5.51951664e-01 -3.20042439e-01\n",
      "  -2.88025320e-01 -8.11092839e-02  7.49347571e-01  3.05027801e-01\n",
      "  -5.13876829e-01 -9.16205014e-01 -5.40330636e-01 -5.12799232e-01\n",
      "   7.23761549e-01 -3.14101133e-01 -2.25576866e-01 -1.35422603e-01\n",
      "   8.72108265e-01  7.11794325e-01]\n",
      " [ 1.16425725e+00 -1.72902356e-01  1.07506698e+00  1.06564712e+00\n",
      "  -7.67054545e-01 -3.90589963e-01 -8.59139496e-02  2.38293157e-01\n",
      "  -6.87266611e-01 -1.26298859e+00 -5.30267543e-01 -1.28884641e+00\n",
      "  -5.15412627e-01 -2.54747610e-01 -1.34555699e+00 -9.19418729e-01\n",
      "  -6.00914335e-01 -8.05919757e-01 -1.24751963e+00 -9.80085579e-01\n",
      "   1.00470663e+00  1.09536279e-01  9.17346905e-01  8.79248967e-01\n",
      "  -3.97441997e-01 -6.96905440e-02  4.10928385e-01  6.37441710e-01\n",
      "   5.70359913e-01 -8.58603036e-01]\n",
      " [ 2.80748791e-01  2.40899174e+00  1.92833867e-01  1.75471117e-01\n",
      "  -9.61294499e-01 -1.14897642e+00 -5.23915164e-01 -5.48850479e-01\n",
      "   1.64403936e-01 -1.45621053e+00  1.96160680e-01  6.85226362e-01\n",
      "   6.87973223e-02  7.97432219e-02 -6.14433502e-02 -6.38266002e-01\n",
      "  -2.35820653e-01 -4.32881026e-01  1.42438108e+00 -7.45947032e-01\n",
      "   1.92254450e-01  1.79251772e+00  7.55446339e-02  7.13005458e-02\n",
      "  -7.84684989e-01 -1.01517702e+00 -5.66158704e-01 -7.33454504e-01\n",
      "   6.17182933e-01 -1.31737747e+00]]\n"
     ]
    }
   ],
   "source": [
    "print (X_test [:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units = 7, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "ann.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy' , metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.7216 - accuracy: 0.5258 - val_loss: 0.6406 - val_accuracy: 0.6783\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.7981 - val_loss: 0.5282 - val_accuracy: 0.8182\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.8873 - val_loss: 0.4561 - val_accuracy: 0.8671\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3699 - accuracy: 0.9155 - val_loss: 0.3986 - val_accuracy: 0.9091\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3172 - accuracy: 0.9390 - val_loss: 0.3509 - val_accuracy: 0.9091\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2760 - accuracy: 0.9413 - val_loss: 0.3128 - val_accuracy: 0.9091\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2428 - accuracy: 0.9437 - val_loss: 0.2826 - val_accuracy: 0.9091\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2159 - accuracy: 0.9484 - val_loss: 0.2579 - val_accuracy: 0.9301\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1941 - accuracy: 0.9531 - val_loss: 0.2363 - val_accuracy: 0.9301\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1760 - accuracy: 0.9554 - val_loss: 0.2200 - val_accuracy: 0.9371\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1610 - accuracy: 0.9577 - val_loss: 0.2037 - val_accuracy: 0.9441\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9671 - val_loss: 0.1906 - val_accuracy: 0.9441\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1368 - accuracy: 0.9695 - val_loss: 0.1792 - val_accuracy: 0.9441\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1271 - accuracy: 0.9695 - val_loss: 0.1688 - val_accuracy: 0.9441\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1187 - accuracy: 0.9742 - val_loss: 0.1612 - val_accuracy: 0.9441\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1116 - accuracy: 0.9789 - val_loss: 0.1540 - val_accuracy: 0.9510\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1050 - accuracy: 0.9812 - val_loss: 0.1480 - val_accuracy: 0.9510\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.9812 - val_loss: 0.1428 - val_accuracy: 0.9510\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0940 - accuracy: 0.9836 - val_loss: 0.1386 - val_accuracy: 0.9510\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0899 - accuracy: 0.9859 - val_loss: 0.1349 - val_accuracy: 0.9580\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0858 - accuracy: 0.9859 - val_loss: 0.1320 - val_accuracy: 0.9580\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0823 - accuracy: 0.9859 - val_loss: 0.1296 - val_accuracy: 0.9580\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0791 - accuracy: 0.9859 - val_loss: 0.1271 - val_accuracy: 0.9510\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.9859 - val_loss: 0.1253 - val_accuracy: 0.9510\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0735 - accuracy: 0.9859 - val_loss: 0.1236 - val_accuracy: 0.9510\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9859 - val_loss: 0.1217 - val_accuracy: 0.9510\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9859 - val_loss: 0.1203 - val_accuracy: 0.9510\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9859 - val_loss: 0.1194 - val_accuracy: 0.9510\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9859 - val_loss: 0.1179 - val_accuracy: 0.9510\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9859 - val_loss: 0.1172 - val_accuracy: 0.9510\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9859 - val_loss: 0.1162 - val_accuracy: 0.9510\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9859 - val_loss: 0.1156 - val_accuracy: 0.9510\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.9883 - val_loss: 0.1146 - val_accuracy: 0.9510\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9883 - val_loss: 0.1140 - val_accuracy: 0.9510\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.9883 - val_loss: 0.1136 - val_accuracy: 0.9510\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0558 - accuracy: 0.9859 - val_loss: 0.1123 - val_accuracy: 0.9510\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.9859 - val_loss: 0.1117 - val_accuracy: 0.9510\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9859 - val_loss: 0.1110 - val_accuracy: 0.9510\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9883 - val_loss: 0.1107 - val_accuracy: 0.9510\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 0.9859 - val_loss: 0.1100 - val_accuracy: 0.9510\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9859 - val_loss: 0.1097 - val_accuracy: 0.9510\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9859 - val_loss: 0.1095 - val_accuracy: 0.9510\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9859 - val_loss: 0.1088 - val_accuracy: 0.9510\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9859 - val_loss: 0.1087 - val_accuracy: 0.9510\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9859 - val_loss: 0.1085 - val_accuracy: 0.9510\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0476 - accuracy: 0.9859 - val_loss: 0.1080 - val_accuracy: 0.9510\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9859 - val_loss: 0.1075 - val_accuracy: 0.9510\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.9859 - val_loss: 0.1079 - val_accuracy: 0.9510\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9859 - val_loss: 0.1072 - val_accuracy: 0.9510\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9859 - val_loss: 0.1074 - val_accuracy: 0.9510\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9859 - val_loss: 0.1069 - val_accuracy: 0.9510\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9859 - val_loss: 0.1066 - val_accuracy: 0.9510\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9859 - val_loss: 0.1064 - val_accuracy: 0.9510\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0434 - accuracy: 0.9859 - val_loss: 0.1062 - val_accuracy: 0.9510\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9859 - val_loss: 0.1061 - val_accuracy: 0.9510\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9859 - val_loss: 0.1061 - val_accuracy: 0.9510\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0419 - accuracy: 0.9859 - val_loss: 0.1060 - val_accuracy: 0.9510\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 0.9859 - val_loss: 0.1055 - val_accuracy: 0.9580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9859 - val_loss: 0.1056 - val_accuracy: 0.9580\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 0.9859 - val_loss: 0.1053 - val_accuracy: 0.9580\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 0.9859 - val_loss: 0.1052 - val_accuracy: 0.9580\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9859 - val_loss: 0.1053 - val_accuracy: 0.9580\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9859 - val_loss: 0.1051 - val_accuracy: 0.9580\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9859 - val_loss: 0.1048 - val_accuracy: 0.9580\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9859 - val_loss: 0.1045 - val_accuracy: 0.9580\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.9859 - val_loss: 0.1042 - val_accuracy: 0.9580\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9859 - val_loss: 0.1043 - val_accuracy: 0.9580\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9859 - val_loss: 0.1041 - val_accuracy: 0.9580\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9859 - val_loss: 0.1034 - val_accuracy: 0.9580\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9859 - val_loss: 0.1040 - val_accuracy: 0.9580\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.9859 - val_loss: 0.1033 - val_accuracy: 0.9580\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9859 - val_loss: 0.1031 - val_accuracy: 0.9580\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.93 - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9859 - val_loss: 0.1036 - val_accuracy: 0.9580\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9859 - val_loss: 0.1028 - val_accuracy: 0.9580\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9859 - val_loss: 0.1025 - val_accuracy: 0.9580\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9859 - val_loss: 0.1027 - val_accuracy: 0.9580\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.9883 - val_loss: 0.1024 - val_accuracy: 0.9580\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 0.9883 - val_loss: 0.1021 - val_accuracy: 0.9580\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 0.9883 - val_loss: 0.1021 - val_accuracy: 0.9580\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 0.9883 - val_loss: 0.1023 - val_accuracy: 0.9580\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9883 - val_loss: 0.1021 - val_accuracy: 0.9580\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9883 - val_loss: 0.1024 - val_accuracy: 0.9580\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 0.9906 - val_loss: 0.1024 - val_accuracy: 0.9580\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9906 - val_loss: 0.1023 - val_accuracy: 0.9580\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 0.9906 - val_loss: 0.1021 - val_accuracy: 0.9580\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9906 - val_loss: 0.1020 - val_accuracy: 0.9580\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9906 - val_loss: 0.1026 - val_accuracy: 0.9580\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9906 - val_loss: 0.1017 - val_accuracy: 0.9580\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9906 - val_loss: 0.1025 - val_accuracy: 0.9580\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9906 - val_loss: 0.1021 - val_accuracy: 0.9580\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.9906 - val_loss: 0.1022 - val_accuracy: 0.9580\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9906 - val_loss: 0.1020 - val_accuracy: 0.9580\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0288 - accuracy: 0.9906 - val_loss: 0.1025 - val_accuracy: 0.9580\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 0.9906 - val_loss: 0.1022 - val_accuracy: 0.9650\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.9906 - val_loss: 0.1025 - val_accuracy: 0.9650\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9906 - val_loss: 0.1027 - val_accuracy: 0.9650\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.9906 - val_loss: 0.1026 - val_accuracy: 0.9580\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0270 - accuracy: 0.9906 - val_loss: 0.1033 - val_accuracy: 0.9650\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9906 - val_loss: 0.1027 - val_accuracy: 0.9650\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.9906 - val_loss: 0.1032 - val_accuracy: 0.9650\n"
     ]
    }
   ],
   "source": [
    "# Training the ANN on the training set\n",
    "history=ann.fit(X_train, Y_train, validation_data = (X_test,Y_test),batch_size = 16, epochs = 100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test set results\n",
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.9)\n",
    "np.set_printoptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report = metrics.classification_report(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        88\n",
      "           1       1.00      0.91      0.95        55\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.95      0.96       143\n",
      "weighted avg       0.97      0.97      0.96       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[88  0]\n",
      " [ 5 50]]\n",
      "\n",
      "Accuracy\n",
      "0.965034965034965\n"
     ]
    }
   ],
   "source": [
    "# Making the confusion matrix, calculating accuracy_score \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "mylist = []\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(Y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "print()\n",
    "\n",
    "# accuracy\n",
    "ac_ann = accuracy_score(Y_test,y_pred)\n",
    "print(\"Accuracy\")\n",
    "print(ac_ann)\n",
    "mylist.append(ac_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.title('Model loss') \n",
    "plt.ylabel('Loss') \n",
    "plt.xlabel('Epoch') \n",
    "plt.legend(['Train', 'Test'], loc='upper left') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
